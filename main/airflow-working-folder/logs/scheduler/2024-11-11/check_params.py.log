[2024-11-11T09:48:26.162+0000] {processor.py:186} INFO - Started process (PID=63) to work on /opt/airflow/dags/check_params.py
[2024-11-11T09:48:26.164+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/check_params.py for tasks to queue
[2024-11-11T09:48:26.167+0000] {logging_mixin.py:190} INFO - [2024-11-11T09:48:26.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/check_params.py
[2024-11-11T09:48:26.245+0000] {processor.py:925} INFO - DAG(s) 'check_params' retrieved from /opt/airflow/dags/check_params.py
[2024-11-11T09:48:26.335+0000] {logging_mixin.py:190} INFO - [2024-11-11T09:48:26.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-11T09:48:26.443+0000] {logging_mixin.py:190} INFO - [2024-11-11T09:48:26.442+0000] {dag.py:4180} INFO - Setting next_dagrun for check_params to 2024-11-10 00:00:00+00:00, run_after=2024-11-11 00:00:00+00:00
[2024-11-11T09:48:26.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/check_params.py took 0.417 seconds
[2024-11-11T09:49:07.649+0000] {processor.py:186} INFO - Started process (PID=57) to work on /opt/airflow/dags/check_params.py
[2024-11-11T09:49:07.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/check_params.py for tasks to queue
[2024-11-11T09:49:07.653+0000] {logging_mixin.py:190} INFO - [2024-11-11T09:49:07.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/check_params.py
[2024-11-11T09:49:07.680+0000] {processor.py:925} INFO - DAG(s) 'check_params' retrieved from /opt/airflow/dags/check_params.py
[2024-11-11T09:49:07.711+0000] {logging_mixin.py:190} INFO - [2024-11-11T09:49:07.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-11T09:49:07.756+0000] {logging_mixin.py:190} INFO - [2024-11-11T09:49:07.756+0000] {dag.py:4180} INFO - Setting next_dagrun for check_params to 2024-11-10 00:00:00+00:00, run_after=2024-11-11 00:00:00+00:00
[2024-11-11T09:49:07.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/check_params.py took 0.149 seconds
[2024-11-11T09:49:38.125+0000] {processor.py:186} INFO - Started process (PID=75) to work on /opt/airflow/dags/check_params.py
[2024-11-11T09:49:38.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/check_params.py for tasks to queue
[2024-11-11T09:49:38.129+0000] {logging_mixin.py:190} INFO - [2024-11-11T09:49:38.128+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/check_params.py
[2024-11-11T09:49:38.164+0000] {processor.py:925} INFO - DAG(s) 'check_params' retrieved from /opt/airflow/dags/check_params.py
[2024-11-11T09:49:38.241+0000] {logging_mixin.py:190} INFO - [2024-11-11T09:49:38.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-11T09:49:38.300+0000] {logging_mixin.py:190} INFO - [2024-11-11T09:49:38.300+0000] {dag.py:4180} INFO - Setting next_dagrun for check_params to 2024-11-10 00:00:00+00:00, run_after=2024-11-11 00:00:00+00:00
[2024-11-11T09:49:39.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/check_params.py took 1.397 seconds
[2024-11-11T09:51:17.784+0000] {processor.py:186} INFO - Started process (PID=97) to work on /opt/airflow/dags/check_params.py
[2024-11-11T09:51:17.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/check_params.py for tasks to queue
[2024-11-11T09:51:17.829+0000] {logging_mixin.py:190} INFO - [2024-11-11T09:51:17.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/check_params.py
[2024-11-11T09:51:18.077+0000] {processor.py:925} INFO - DAG(s) 'check_params' retrieved from /opt/airflow/dags/check_params.py
[2024-11-11T09:51:55.794+0000] {logging_mixin.py:190} INFO - [2024-11-11T09:51:55.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2024-11-11T09:51:56.134+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
psycopg2.OperationalError: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

[SQL: SELECT dag.dag_display_name, dag.dag_id, dag.root_dag_id, dag.is_paused, dag.is_subdag, dag.is_active, dag.last_parsed_time, dag.last_pickled, dag.last_expired, dag.scheduler_lock, dag.pickle_id, dag.fileloc, dag.processor_subdir, dag.owners, dag.description, dag.default_view, dag.schedule_interval, dag.timetable_description, dag.dataset_expression, dag.max_active_tasks, dag.max_active_runs, dag.max_consecutive_failed_dag_runs, dag.has_task_concurrency_limits, dag.has_import_errors, dag.next_dagrun, dag.next_dagrun_data_interval_start, dag.next_dagrun_data_interval_end, dag.next_dagrun_create_after, dag_tag_1.name, dag_tag_1.dag_id AS dag_id_1, dag_schedule_dataset_reference_1.dataset_id, dag_schedule_dataset_reference_1.dag_id AS dag_id_2, dag_schedule_dataset_reference_1.created_at, dag_schedule_dataset_reference_1.updated_at, dag_schedule_dataset_alias_reference_1.alias_id, dag_schedule_dataset_alias_reference_1.dag_id AS dag_id_3, dag_schedule_dataset_alias_reference_1.created_at AS created_at_1, dag_schedule_dataset_alias_reference_1.updated_at AS updated_at_1, task_outlet_dataset_reference_1.dataset_id AS dataset_id_1, task_outlet_dataset_reference_1.dag_id AS dag_id_4, task_outlet_dataset_reference_1.task_id, task_outlet_dataset_reference_1.created_at AS created_at_2, task_outlet_dataset_reference_1.updated_at AS updated_at_2 
FROM dag LEFT OUTER JOIN dag_tag AS dag_tag_1 ON dag.dag_id = dag_tag_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_reference AS dag_schedule_dataset_reference_1 ON dag.dag_id = dag_schedule_dataset_reference_1.dag_id LEFT OUTER JOIN dag_schedule_dataset_alias_reference AS dag_schedule_dataset_alias_reference_1 ON dag.dag_id = dag_schedule_dataset_alias_reference_1.dag_id LEFT OUTER JOIN task_outlet_dataset_reference AS task_outlet_dataset_reference_1 ON dag.dag_id = task_outlet_dataset_reference_1.dag_id 
WHERE dag.dag_id IN (%(dag_id_5_1)s) FOR UPDATE OF dag]
[parameters: {'dag_id_5_1': 'check_params'}]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
